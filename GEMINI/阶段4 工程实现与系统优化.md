-   首先要了解KV缓存
-   **1. 高性能核函数 (High-Performance Kernels)**
    -   
    -   **技术：**
        -   
        -   **FlashAttention v1/v2/v3：** 理论与实践的结合。
        -   **Triton 语言：** 学习使用 Python-based 的 Triton 语言为你的特定注意力变种编写高效的 GPU 核函数。
        -   **CUDA 编程：** 在需要极致性能或 Triton 无法满足的场景下，直接编写 CUDA C++ 核函数。
-   **2. 分布式训练 (Distributed Training)**
    -   
    -   **挑战：** 如何在多卡、多机环境下高效计算注意力。
    -   **技术：**
        -   
        -   **张量并行 (Tensor Parallelism):** Megatron-LM 中对 Multi-Head Attention 的并行化处理。
        -   **序列并行 (Sequence Parallelism):** 在长序列场景下，沿序列长度维度进行切分。
        -   **分布式优化器：** ZeRO 等技术如何处理注意力的权重和激活值。
-   **3. 推理优化 (Inference Optimization)**
    -   
    -   **核心：** K/V 缓存的管理与优化、模型量化、剪枝、蒸馏等。
    -   **技术：**
        -   
        -   **PagedAttention:** vLLM 中使用的技术，有效管理 K/V 缓存，减少内存浪费。
        -   **Speculative Decoding:** 用一个小模型预测多个 token，再由大模型一次性验证，加速推理。